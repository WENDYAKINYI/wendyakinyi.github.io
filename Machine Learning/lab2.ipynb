{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a38c6133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faf7cb6",
   "metadata": {},
   "source": [
    "### Create a data set\n",
    "- Load the Diabetes data bunch from SciKit Learn\n",
    "    - The Diabetes data bunch is located in sklearn.datasets\n",
    "    - Include $as\\_frame=True$ in the fetch command to ease creating a DataFrame\n",
    "- Create a Pandas DataFrame\n",
    "- Show the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d19213a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age       sex       bmi        bp        s1        s2        s3  \\\n",
      "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
      "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
      "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
      "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
      "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
      "\n",
      "         s4        s5        s6  \n",
      "0 -0.002592  0.019907 -0.017646  \n",
      "1 -0.039493 -0.068332 -0.092204  \n",
      "2 -0.002592  0.002861 -0.025930  \n",
      "3  0.034309  0.022688 -0.009362  \n",
      "4 -0.002592 -0.031988 -0.046641  \n"
     ]
    }
   ],
   "source": [
    "# Load the diabetes dataset\n",
    "diabetes = load_diabetes(as_frame=True)\n",
    "\n",
    "# Create a pandas dataframe\n",
    "diabetes_df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "\n",
    "# Display the first few rows\n",
    "print(diabetes_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c1306c",
   "metadata": {},
   "source": [
    "### Split the DataFrame into Training and Testing\n",
    "- The target variable is \"target\"\n",
    "- Set aside 20% of the data for testing\n",
    "- Show the dimensions of the Training and Testing Input data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38ce6c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset partitioning:\n",
      "Training set shape: (353, 10)\n",
      "Testing set shape: (89, 10)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Add the target variable to the DataFrame\n",
    "diabetes_df[\"target\"] = diabetes.target\n",
    "\n",
    "X = diabetes_df.drop(columns = ['target'])\n",
    "y = diabetes_df['target']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=204)\n",
    "\n",
    "# Show the dimensions of the Training and Testing data sets\n",
    "\n",
    "print(\"\\nDataset partitioning:\")\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a0f995",
   "metadata": {},
   "source": [
    "### Construct a simple model\n",
    "- Instantiate a Decision Tree Regressor with default hyperparameter settings\n",
    "- Fit the regressor with the Training data\n",
    "- Extract and show the depth of the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afe0caeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth of the Decision Tree: 18\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Instantiate a Decision Tree Regressor with default hyperparameter settings\n",
    "\n",
    "\n",
    "dt_model = DecisionTreeRegressor(random_state=204)\n",
    "\n",
    "\n",
    "# Fit the regressor to the training data\n",
    "\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Extract and show the depth of the tree\n",
    "# Hint: Use .get_depth() to get the depth of the tree\n",
    "\n",
    "\n",
    "tree_depth = dt_model.get_depth()\n",
    "\n",
    "\n",
    "# tree_leaves = dt_model.get_n_leaves()\n",
    "\n",
    "\n",
    "print(\"Depth of the Decision Tree:\", tree_depth)\n",
    "\n",
    "\n",
    "# print(\"Number of leaves the Decision Tree:\", tree_leaves)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37f7370",
   "metadata": {},
   "source": [
    "### Evaluate the performance of the simple model \n",
    "- Calculate the RMSE on the Training and Testing Set\n",
    "- Save the RMSE on the Testing Data into a variable for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d24ca5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on Training Set: 0.0\n",
      "RMSE on Testing Set: 72.1490342698183\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Make predictions on the training and testing sets\n",
    "y_train_pred = dt_model.predict(X_train)\n",
    "y_test_pred = dt_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE for the training set\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "# Calculate RMSE for the testing set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Save the RMSE on the testing data into a variable for later use\n",
    "simple_testing_rmse = rmse_test\n",
    "\n",
    "# Print the RMSE values\n",
    "print(\"RMSE on Training Set:\", rmse_train)\n",
    "print(\"RMSE on Testing Set:\", rmse_test)\n",
    "\n",
    "# Notes\n",
    "# a zero training error with a much higher testing error indicates overfitting.\n",
    "# The high testing RMSE indicates that the model isnt generalizing well and is likely too complex and has learned the noise in the training data thus needs\n",
    "# to be simplified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1104870-7636-4858-965f-56f9a6300085",
   "metadata": {},
   "source": [
    "### Calculate the baseline metrics from cross validation\n",
    "- Execute $cross\\_validate$, with the decision tree regressor instantiated above, the Training Data, cv=3, and the following evaluation metrics:\n",
    "    - Root Mean Squared Error\n",
    "    - Mean Absolute Error\n",
    "- Save the results into a variable\n",
    "- Show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ceb85acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fit_time  score_time  test_rmse  train_rmse   test_mae  train_mae\n",
      "0  0.041466    0.034521  80.685149         0.0  65.516949        0.0\n",
      "1  0.019363    0.006017  79.191198         0.0  60.161017        0.0\n",
      "2  0.012376    0.004987  82.546905         0.0  64.897436        0.0\n",
      "\n",
      "Mean CV Scores:\n",
      "Mean RMSE: 80.8077502562048\n",
      "Mean MAE: 63.52513399971027\n",
      "Mean RMSE: 0.0\n",
      "Mean MAE: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define custom scorers for RMSE and MAE\n",
    "rmse_scorer = make_scorer(lambda y_true, y_pred: np.sqrt(\n",
    "    mean_squared_error(y_true, y_pred)))\n",
    "mae_scorer = make_scorer(mean_absolute_error)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = cross_validate(\n",
    "    dt_model,  # The Decision Tree Regressor\n",
    "    X_train,        # Training input data\n",
    "    y_train,        # Training target data\n",
    "    cv=3,           # Number of cross-validation folds\n",
    "    scoring={\n",
    "        'rmse': rmse_scorer,  # RMSE scorer\n",
    "        'mae': mae_scorer     # MAE scorer\n",
    "    },\n",
    "    return_train_score=True  # Includes training scores in the results\n",
    ")\n",
    "\n",
    "# Save the results\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "\n",
    "print(cv_results_df)\n",
    "# To get the mean scores:\n",
    "print(\"\\nMean CV Scores:\")\n",
    "\n",
    "print(f\"Mean RMSE: {--cv_results['test_rmse'].mean()}\")\n",
    "print(f\"Mean MAE: {--cv_results['test_mae'].mean()}\")\n",
    "print(f\"Mean RMSE: {--cv_results['train_rmse'].mean()}\")\n",
    "print(f\"Mean MAE: {--cv_results['train_mae'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f344ab",
   "metadata": {},
   "source": [
    "- Show standard deviation and mean RMSE for each fold of cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93e299ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE Results:\n",
      "Train RMSE (mean): 0.0000\n",
      "Train RMSE (std): 0.0000\n",
      "Test RMSE (mean): 80.8078\n",
      "Test RMSE (std): 1.3727\n",
      "\n",
      "RMSE for Each Fold:\n",
      "Fold 1: Train RMSE = 0.0000, Test RMSE = 80.6851, \n",
      "Fold 2: Train RMSE = 0.0000, Test RMSE = 79.1912, \n",
      "Fold 3: Train RMSE = 0.0000, Test RMSE = 82.5469, \n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Extract RMSE scores for each fold\n",
    "train_rmse_scores = cv_results['train_rmse']\n",
    "test_rmse_scores = cv_results['test_rmse']\n",
    "\n",
    "# Calculate mean and standard deviation for RMSE scores\n",
    "train_rmse_mean = train_rmse_scores.mean()\n",
    "train_rmse_std = train_rmse_scores.std()\n",
    "test_rmse_mean = test_rmse_scores.mean()\n",
    "test_rmse_std = test_rmse_scores.std()\n",
    "\n",
    "# Show the results\n",
    "print(\"Cross-Validation RMSE Results:\")\n",
    "print(f\"Train RMSE (mean): {train_rmse_mean:.4f}\")\n",
    "print(f\"Train RMSE (std): {train_rmse_std:.4f}\")\n",
    "print(f\"Test RMSE (mean): {test_rmse_mean:.4f}\")\n",
    "print(f\"Test RMSE (std): {test_rmse_std:.4f}\")\n",
    "\n",
    "# Show RMSE for each fold\n",
    "print(\"\\nRMSE for Each Fold:\")\n",
    "for fold, (train_rmse, test_rmse) in enumerate(zip(train_rmse_scores, test_rmse_scores), start=1):\n",
    "    print(f\"Fold {fold}: Train RMSE = {\n",
    "          train_rmse:.4f}, Test RMSE = {test_rmse:.4f}, \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aabe097-cd63-41f7-bef7-967dcc71ca53",
   "metadata": {},
   "source": [
    "### Brute Force identification of the optimal max_depth setting\n",
    "- Write a loop that will iteratively execute $cross\\_validate$ using the decision tree regressor and with the max_depth setting in the range from one to the maximum depth found above\n",
    "    - Tip: The max_depth hyperparameter can be updated in the loop by calling $set\\_params()$\n",
    "    - Within $cross\\_validate$, use three folds, the Training Data, and calculate the RMSE scores\n",
    "    - For each value of depth, print the depth and average RMSE\n",
    "    - From the output printed, identify the optimal depth for each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "095d9b35-7289-493e-8994-5493143f125b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 1, Average Test RMSE: 67.4903\n",
      "Depth: 2, Average Test RMSE: 63.3295\n",
      "Depth: 3, Average Test RMSE: 62.9330\n",
      "Depth: 4, Average Test RMSE: 67.2458\n",
      "Depth: 5, Average Test RMSE: 70.0244\n",
      "Depth: 6, Average Test RMSE: 73.4565\n",
      "Depth: 7, Average Test RMSE: 75.0895\n",
      "Depth: 8, Average Test RMSE: 78.8285\n",
      "Depth: 9, Average Test RMSE: 80.1774\n",
      "Depth: 10, Average Test RMSE: 81.3454\n",
      "Depth: 11, Average Test RMSE: 82.3884\n",
      "Depth: 12, Average Test RMSE: 83.3118\n",
      "Depth: 13, Average Test RMSE: 82.8036\n",
      "Depth: 14, Average Test RMSE: 81.8235\n",
      "Depth: 15, Average Test RMSE: 80.5003\n",
      "Depth: 16, Average Test RMSE: 81.4539\n",
      "Depth: 17, Average Test RMSE: 81.4878\n",
      "Depth: 18, Average Test RMSE: 81.5140\n",
      "\n",
      "Optimal Depth: 3, Best Average Test RMSE: 62.9330\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Initialize variables to store the best depth and corresponding RMSE\n",
    "best_depth = None\n",
    "best_rmse = float('inf')\n",
    "\n",
    "# Loop through max_depth values from 1 to the maximum depth\n",
    "for depth in range(1, tree_depth + 1):\n",
    "    # Update the max_depth hyperparameter\n",
    "    dt_model.set_params(max_depth=depth)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_results = cross_validate(\n",
    "        dt_model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=3,\n",
    "        scoring={'rmse': make_scorer(lambda y_true, y_pred: np.sqrt(\n",
    "            mean_squared_error(y_true, y_pred)))},\n",
    "        return_train_score=True\n",
    "    )\n",
    "\n",
    "    # Calculate the average RMSE for the testing set\n",
    "    avg_test_rmse = cv_results['test_rmse'].mean()\n",
    "\n",
    "    # Print the depth and average RMSE\n",
    "    print(f\"Depth: {depth}, Average Test RMSE: {avg_test_rmse:.4f}\")\n",
    "\n",
    "    # Check if this depth is the best so far\n",
    "    if avg_test_rmse < best_rmse:\n",
    "        best_rmse = avg_test_rmse\n",
    "        best_depth = depth\n",
    "\n",
    "# Print the optimal depth and corresponding RMSE\n",
    "print(f\"\\nOptimal Depth: {\n",
    "      best_depth}, Best Average Test RMSE: {best_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b143539f",
   "metadata": {},
   "source": [
    "### Use GridSearchCV to identify the optimal depth\n",
    "- Construct a grid to search the max_depth setting from one to the maximum depth found above\n",
    "- Instantiate GridSearchCV with the following:\n",
    "    - estimator = decision tree regressor\n",
    "    - param_grid = the above grid for max_depth\n",
    "    - cv = 3\n",
    "    - refit = 'neg_root_mean_squared_error'\n",
    "    - scoring= ['neg_root_mean_squared_error', 'neg_mean_absolute_error']\n",
    "- Call .fit() with the Training Data\n",
    "- With multiple scoring metrics being calculated, .best_params_ and .best_score_ correspond to the refit strategy\n",
    "- Compare .best_params_ and .best_score_ to the values found from brute force calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d12fdaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from GridSearchCV: {'max_depth': 3}\n",
      "Best RMSE from GridSearchCV: 62.93302278782746\n",
      "\n",
      "Comparison to Brute-Force Results:\n",
      "Brute-Force Optimal Depth: 3, Best RMSE: 62.9330\n",
      "GridSearchCV Optimal Depth: 3, Best RMSE: 62.9330\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Construct the grid for max_depth\n",
    "param_grid = {'max_depth': list(range(1, tree_depth + 1))}\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=dt_model,  \n",
    "    param_grid=param_grid,     \n",
    "    cv=3,                      \n",
    "    refit='neg_root_mean_squared_error',  # Refit using RMSE\n",
    "    scoring=['neg_root_mean_squared_error',\n",
    "             'neg_mean_absolute_error'],  \n",
    "    return_train_score=True    \n",
    ")\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_  \n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters from GridSearchCV:\", best_params)\n",
    "print(\"Best RMSE from GridSearchCV:\", best_score)\n",
    "\n",
    "# Compare to brute-force results\n",
    "print(\"\\nComparison to Brute-Force Results:\")\n",
    "print(f\"Brute-Force Optimal Depth: {best_depth}, Best RMSE: {best_rmse:.4f}\")\n",
    "print(f\"GridSearchCV Optimal Depth: {\n",
    "      best_params['max_depth']}, Best RMSE: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117ebc7b-a10f-45eb-b5e8-e72e03174a58",
   "metadata": {},
   "source": [
    "### Evaluate the final model\n",
    "- Assume identifying the optimal value of max_depth will construct the optimal tree\n",
    "- Calculate the RMSE on the Training and Testing Set from the tree found from Grid Search above\n",
    "- Compare the RMSE on the Testing Data from the default setting and the tuned setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf6812db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RMSE from Testing Data with default settings:': 72.1490342698183,\n",
       " 'RMSE from Testing Data after tuning settings:': 60.237152516027294,\n",
       " 'RMSE from Training Data with default settings:': 0.0,\n",
       " 'RMSE from Training Data after tuning settings:': 54.364994825858155}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the final model with the optimal max_depth\n",
    "final_model = DecisionTreeRegressor(\n",
    "    max_depth=best_params['max_depth'], random_state=204)\n",
    "\n",
    "# Fit the model using the training data\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on training and testing sets\n",
    "y_train_pred_final = final_model.predict(X_train)\n",
    "y_test_pred_final = final_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE for training and testing sets\n",
    "rmse_train_final = np.sqrt(mean_squared_error(y_train, y_train_pred_final))\n",
    "rmse_test_final = np.sqrt(mean_squared_error(y_test, y_test_pred_final))\n",
    "\n",
    "# Compare RMSE from default and tuned settings\n",
    "rmse_comparison = {\n",
    "    \"RMSE from Testing Data with default settings:\": rmse_test,\n",
    "    \"RMSE from Testing Data after tuning settings:\": rmse_test_final,\n",
    "    \"RMSE from Training Data with default settings:\": rmse_train,\n",
    "    \"RMSE from Training Data after tuning settings:\": rmse_train_final\n",
    "    \n",
    "}\n",
    "\n",
    "rmse_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc195edc",
   "metadata": {},
   "source": [
    "The tuned model performs better on the testing set, indicating that tuning the settings improved the model's performance on unseen (testing) data, leading to more accurate predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
